# Image Captioning with Microsoft COCO Dataset
Students <br>
* Sakshi Singla <br>
* Ivette Sulca <br>
### Abstract: 
The goal of image captioning is to convert a given input image into a natural language description. The encoder-decoder framework is used for this task. The image encoder is a convolutional neural network (CNN). We used resnet-152 model pretrained on the ILSVRC-2012-CLS image classification dataset. The decoder is a seq-to-seq GRU (RNN)  network. The model is evaluated both qualitatively and quantitatively. BLEU-n scores (metric used in machine translation to evaluate the quality of generated sentences) are used for quantitative evaluation.
